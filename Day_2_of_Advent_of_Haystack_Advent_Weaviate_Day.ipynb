{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lL7Y3zl5NYAy"
      },
      "source": [
        "# Advent of Haystack: Day 2\n",
        "\n",
        "In this challenge, your mission is to help a couple of fictional elves in the film \"A Very Weaviate Christmas\".\n",
        "1. Find out what's happening in the film \"A Very Weaviate Christmas\"\n",
        "2. This will lead you to a clue that will let you discover which Weaviate Collection to peak into.\n",
        "3. While submitting the challenge, tell us what you find there!\n",
        "\n",
        "\n",
        "### Components to use:\n",
        "1. [`OpenAITextEmbedder`](https://docs.haystack.deepset.ai/docs/openaitextembedder)\n",
        "2. [`OpenAIGenerator`](https://docs.haystack.deepset.ai/docs/openaigenerator)\n",
        "3. [`PromptBuilder`](https://docs.haystack.deepset.ai/docs/promptbuilder)\n",
        "4. [`WeaviateDocumentStore`](https://docs.haystack.deepset.ai/docs/weaviatedocumentstore)\n",
        "5. [`WeaviateEmbeddingRetriever`](https://docs.haystack.deepset.ai/reference/integrations-weaviate#weaviateembeddingretriever)\n",
        "\n",
        "\n",
        "üéÑ **Your task is to complete steps 3 and 4**. But make sure you run the code cells before. You should know what each prior step is doing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VVczHaPYOGxT"
      },
      "source": [
        "## 1) Setup and Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hdiFsnQDWzP0"
      },
      "outputs": [],
      "source": [
        "!pip install haystack-ai weaviate-haystack\n",
        "!pip install -q --upgrade openai # not to get the OpenAI proxies error: https://community.openai.com/t/error-with-openai-1-56-0-client-init-got-an-unexpected-keyword-argument-proxies/1040332/2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VtYq1ESqMB3K"
      },
      "source": [
        "To get started, first provide your API keys below. We're providing you with a read-only API Key for Weaviate.\n",
        "\n",
        "For this challenge, we've prepared a Weaviate Collection for you which contains lots of movies and their overviews."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FL3rTDBtMBOj",
        "outputId": "fbc41d2d-ec98-4c93-c79e-a2b31ad02c58"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The dotenv extension is already loaded. To reload it, use:\n",
            "  %reload_ext dotenv\n"
          ]
        }
      ],
      "source": [
        "%load_ext dotenv\n",
        "%dotenv\n",
        "\n",
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "os.environ[\"WEAVIATE_API_KEY\"] = \"b3jhGwa4NkLGjaq3v1V1vh1pTrlKjePZSt91\"\n",
        "\n",
        "huggingface_api_key = os.getenv(\"HUGGINGFACE_API_KEY\")\n",
        "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "#if \"OPENAI_API_KEY\" not in os.environ:\n",
        "#os.environ[\"OPENAI_API_KEY\"] = getpass(\"Enter OpenAI API key:\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PYsyzFI0MvHF"
      },
      "source": [
        "## 2) Weaviate Setup\n",
        "\n",
        "Next, you can connect to the right `WeaviateDocumentStore` (we've already added the right code for you below with the client URL in place).\n",
        "\n",
        "In this document store, there are many movies, their titles and ther overviews."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "EbTdrvUgZoku"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/homebrew/Caskroom/miniforge/base/envs/advent_haystack_24/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "from haystack_integrations.document_stores.weaviate import WeaviateDocumentStore, AuthApiKey\n",
        "from haystack import Document\n",
        "import os\n",
        "\n",
        "\n",
        "auth_client_secret = AuthApiKey()\n",
        "\n",
        "document_store = WeaviateDocumentStore(url=\"https://zgvjwlycsr6p5j1ziuyea.c0.europe-west3.gcp.weaviate.cloud\",\n",
        "                                       auth_client_secret=auth_client_secret)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4qTWIDu_OpSF"
      },
      "source": [
        "## 3) The RAG Pipeline\n",
        "\n",
        "Now, you're on your own. Complete the code blocks below.\n",
        "\n",
        "First, create a RAG pipeline that can answer questions based on the overviews of the movies in your `document_store`.\n",
        "\n",
        "‚≠êÔ∏è You should then be able to run the pipeline and answer the questions \"What happens in the film 'A Very Weaviate Christmas'?\"\n",
        "\n",
        "**üíö Hint 1:** The embedding model that was used to populate the vectors was `text-embedding-3-small` by OpenAI.\n",
        "\n",
        "**üíô Hint 2:** We've added an import to the OpenAIGenerator but feel free to use something else!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "aVUii4r1cr3f"
      },
      "outputs": [],
      "source": [
        "from haystack import Pipeline\n",
        "from haystack.components.embedders import OpenAITextEmbedder\n",
        "from haystack.components.generators import HuggingFaceAPIGenerator\n",
        "from haystack.components.builders import PromptBuilder\n",
        "from haystack_integrations.components.retrievers.weaviate import WeaviateEmbeddingRetriever\n",
        "from haystack.utils import Secret\n",
        "\n",
        "text_embedder = OpenAITextEmbedder(api_key=Secret.from_token(openai_api_key), model=\"text-embedding-3-small\")\n",
        "template = \"\"\"\n",
        "Given the following information, answer the question.\n",
        "\n",
        "Context:\n",
        "{% for document in documents %}\n",
        "    {{ document.content }}\n",
        "{% endfor %}\n",
        "\n",
        "Question: {{question}}\n",
        "Answer:\n",
        "\"\"\"\n",
        "prompt_builder = PromptBuilder(template = template)\n",
        "generator = HuggingFaceAPIGenerator(api_type=\"serverless_inference_api\",\n",
        "                                    api_params={\"model\": \"mistralai/Mistral-Nemo-Instruct-2407\"},#\"Qwen/QwQ-32B-Preview\"},\n",
        "                                    token=Secret.from_token(huggingface_api_key))\n",
        "embedding_retriever = WeaviateEmbeddingRetriever(document_store=document_store)\n",
        "\n",
        "rag = Pipeline()\n",
        "rag.add_component(\"text_embedder\", text_embedder)\n",
        "rag.add_component(\"retriever\", embedding_retriever)\n",
        "rag.add_component(\"prompt_builder\", prompt_builder)\n",
        "rag.add_component(\"llm\", generator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<haystack.core.pipeline.pipeline.Pipeline object at 0x17d401160>\n",
              "üöÖ Components\n",
              "  - text_embedder: OpenAITextEmbedder\n",
              "  - retriever: WeaviateEmbeddingRetriever\n",
              "  - prompt_builder: PromptBuilder\n",
              "  - llm: HuggingFaceAPIGenerator\n",
              "üõ§Ô∏è Connections\n",
              "  - text_embedder.embedding -> retriever.query_embedding (List[float])\n",
              "  - retriever.documents -> prompt_builder.documents (List[Document])\n",
              "  - prompt_builder.prompt -> llm.prompt (str)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rag.connect(\"text_embedder.embedding\", \"retriever.query_embedding\")\n",
        "rag.connect(\"retriever\", \"prompt_builder\")\n",
        "rag.connect(\"prompt_builder.prompt\", \"llm.prompt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "OsiP8tIVfXqD"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " In 'A Very Weaviate Christmas', two of Santa's elves, Daniel and Philip, are on a mission to recover stolen vectors hidden in an unknown Collection and return them to 'Santas_Grotto' before Christmas Day.\n"
          ]
        }
      ],
      "source": [
        "query = \"What happens in the film 'A Very Weaviate Christmas'?\"\n",
        "reply = rag.run({\"text_embedder\": {\"text\": query}, \"prompt_builder\": {\"question\": query}})\n",
        "\n",
        "print(reply[\"llm\"][\"replies\"][0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iEldTiRmShUk"
      },
      "source": [
        "## 4) Solve the Mystery\n",
        "\n",
        "By this point, you should know what's happening.. There is a Collection where everything has been hidden.\n",
        "\n",
        "Complete the code cell below by providing the right Collection name, and tell us the following:\n",
        "\n",
        "1. Who is the culprit? Watch out, because there may be `decoys`.\n",
        "2. What have they stolen?\n",
        "\n",
        "**üíö Hint:** Once you've connected to the right collection, take a look at all the Objects in there. Then, you may be able to use filters to avoid the decoys!\n",
        "\n",
        "- [Weaviate Documentation: Read all Objects](https://weaviate.io/developers/weaviate/manage-data/read-all-objects)\n",
        "- [Weaviate Documentation: Filters](https://weaviate.io/developers/weaviate/search/filters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "4US7AdElQ2Zk"
      },
      "outputs": [],
      "source": [
        "import weaviate\n",
        "\n",
        "from weaviate.classes.init import Auth\n",
        "\n",
        "headers = {\"X-OpenAI-Api-Key\": openai_api_key}\n",
        "client = weaviate.connect_to_weaviate_cloud(cluster_url=\"https://zgvjwlycsr6p5j1ziuyea.c0.europe-west3.gcp.weaviate.cloud\",\n",
        "                                            auth_credentials=Auth.api_key(os.getenv(\"WEAVIATE_API_KEY\")),\n",
        "                                            headers=headers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "schema = client.collections.list_all()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'Default': _CollectionConfigSimple(name='Default', description=None, generative_config=None, properties=[_Property(name='_original_id', description=None, data_type=<DataType.TEXT: 'text'>, index_filterable=True, index_range_filters=False, index_searchable=True, nested_properties=None, tokenization=<Tokenization.WORD: 'word'>, vectorizer_config=None, vectorizer='none'), _Property(name='content', description=None, data_type=<DataType.TEXT: 'text'>, index_filterable=True, index_range_filters=False, index_searchable=True, nested_properties=None, tokenization=<Tokenization.WORD: 'word'>, vectorizer_config=None, vectorizer='none'), _Property(name='dataframe', description=None, data_type=<DataType.TEXT: 'text'>, index_filterable=True, index_range_filters=False, index_searchable=True, nested_properties=None, tokenization=<Tokenization.WORD: 'word'>, vectorizer_config=None, vectorizer='none'), _Property(name='blob_data', description=None, data_type=<DataType.BLOB: 'blob'>, index_filterable=True, index_range_filters=False, index_searchable=False, nested_properties=None, tokenization=None, vectorizer_config=None, vectorizer='none'), _Property(name='blob_mime_type', description=None, data_type=<DataType.TEXT: 'text'>, index_filterable=True, index_range_filters=False, index_searchable=True, nested_properties=None, tokenization=<Tokenization.WORD: 'word'>, vectorizer_config=None, vectorizer='none'), _Property(name='score', description=None, data_type=<DataType.NUMBER: 'number'>, index_filterable=True, index_range_filters=False, index_searchable=False, nested_properties=None, tokenization=None, vectorizer_config=None, vectorizer='none'), _Property(name='release_date', description=\"This property was generated by Weaviate's auto-schema feature on Fri Nov 29 09:38:26 2024\", data_type=<DataType.DATE: 'date'>, index_filterable=True, index_range_filters=False, index_searchable=False, nested_properties=None, tokenization=None, vectorizer_config=None, vectorizer='none'), _Property(name='title', description=\"This property was generated by Weaviate's auto-schema feature on Fri Nov 29 09:38:26 2024\", data_type=<DataType.TEXT: 'text'>, index_filterable=True, index_range_filters=False, index_searchable=True, nested_properties=None, tokenization=<Tokenization.WORD: 'word'>, vectorizer_config=None, vectorizer='none')], references=[], reranker_config=None, vectorizer_config=None, vectorizer=<Vectorizers.NONE: 'none'>, vector_config=None),\n",
              " 'Santas_Grotto': _CollectionConfigSimple(name='Santas_Grotto', description=None, generative_config=None, properties=[_Property(name='plot', description=None, data_type=<DataType.TEXT: 'text'>, index_filterable=True, index_range_filters=False, index_searchable=True, nested_properties=None, tokenization=<Tokenization.WORD: 'word'>, vectorizer_config=_PropertyVectorizerConfig(skip=False, vectorize_property_name=True), vectorizer='text2vec-openai'), _Property(name='decoy', description=None, data_type=<DataType.BOOL: 'boolean'>, index_filterable=True, index_range_filters=False, index_searchable=False, nested_properties=None, tokenization=None, vectorizer_config=_PropertyVectorizerConfig(skip=False, vectorize_property_name=True), vectorizer='text2vec-openai')], references=[], reranker_config=None, vectorizer_config=_VectorizerConfig(vectorizer=<Vectorizers.TEXT2VEC_OPENAI: 'text2vec-openai'>, model={'baseURL': 'https://api.openai.com', 'model': 'text-embedding-3-small'}, vectorize_collection_name=True), vectorizer=<Vectorizers.TEXT2VEC_OPENAI: 'text2vec-openai'>, vector_config=None)}"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "schema"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Provide the name of the collection in client.collections.get() below üëá\n",
        "plot = client.collections.get(\"Santas_Grotto\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'plot': 'Tuana is here with not just all the vectors but also all the presents that are supposed to be delivered around the World!', 'decoy': False}\n",
            "{'plot': \"Sebastian is here, but he seems unsure what's going on\", 'decoy': True}\n",
            "{'plot': \"JP is here, looks like he's feasting on cookies\", 'decoy': True}\n"
          ]
        }
      ],
      "source": [
        "for item in plot.iterator(\n",
        "    include_vector=True  # If using named vectors, you can specify ones to include e.g. ['title', 'body'], or True to include all\n",
        "):\n",
        "    print(item.properties)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'plot': 'Tuana is here with not just all the vectors but also all the presents that are supposed to be delivered around the World!', 'decoy': False}\n"
          ]
        }
      ],
      "source": [
        "from weaviate.classes.query import Filter\n",
        "\n",
        "filtered_response = plot.query.fetch_objects(\n",
        "    filters=Filter.by_property(\"decoy\").equal(False)\n",
        ")\n",
        "\n",
        "for o in filtered_response.objects:\n",
        "    print(o.properties)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python (advent_haystack_24)",
      "language": "python",
      "name": "advent_haystack_24"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
